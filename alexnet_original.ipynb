{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from model import AlexNet\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#device : GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "    \"val\": transforms.Compose([transforms.Resize((224, 224)),  # cannot 224, must (224, 224)\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "data_root = os.getcwd()\n",
    "image_path = data_root + \"/data/\"  # flower data set path\n",
    "train_dataset = datasets.ImageFolder(root=image_path + \"/train\",\n",
    "                                     transform=data_transform[\"train\"])\n",
    "train_num = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in cd_list.items())\n",
    "# write dict into json file\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) <class 'torch.Tensor'>\n",
      "tensor(4) 4 <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(root=image_path + \"/val\",\n",
    "                                        transform=data_transform[\"val\"])\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=0)\n",
    "\n",
    "test_data_iter = iter(validate_loader)\n",
    "test_image, test_label = test_data_iter.next()\n",
    "print(test_image[0].size(),type(test_image[0]))\n",
    "print(test_label[0],test_label[0].item(),type(test_label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet(num_classes=7, init_weights=False)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
    "\n",
    "save_path = './AlexNet.pth'\n",
    "\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 100%[**************************************************->]1.822\n",
      "95.65430100799858\n",
      "[epoch 1] train_loss: 1.903  test_accuracy: 0.251\n",
      "train loss: 100%[**************************************************->]1.722\n",
      "99.09808918000272\n",
      "[epoch 2] train_loss: 1.485  test_accuracy: 0.395\n",
      "train loss: 100%[**************************************************->]1.167\n",
      "93.32256036800027\n",
      "[epoch 3] train_loss: 1.293  test_accuracy: 0.538\n",
      "train loss: 100%[**************************************************->]1.467\n",
      "99.33429445299771\n",
      "[epoch 4] train_loss: 1.193  test_accuracy: 0.531\n",
      "train loss: 100%[**************************************************->]0.808\n",
      "101.47223717499946\n",
      "[epoch 5] train_loss: 1.139  test_accuracy: 0.414\n",
      "train loss: 100%[**************************************************->]0.468\n",
      "103.29923930599762\n",
      "[epoch 6] train_loss: 1.102  test_accuracy: 0.586\n",
      "train loss: 100%[**************************************************->]0.480\n",
      "105.37922006699955\n",
      "[epoch 7] train_loss: 1.035  test_accuracy: 0.689\n",
      "train loss: 100%[**************************************************->]0.914\n",
      "107.94124120700144\n",
      "[epoch 8] train_loss: 1.043  test_accuracy: 0.600\n",
      "train loss: 100%[**************************************************->]1.198\n",
      "111.53679135300263\n",
      "[epoch 9] train_loss: 0.995  test_accuracy: 0.629\n",
      "train loss: 100%[**************************************************->]0.787\n",
      "109.09110785099983\n",
      "[epoch 10] train_loss: 0.966  test_accuracy: 0.660\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # train\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    t1 = time.perf_counter()\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images.to(device))\n",
    "        loss = loss_function(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print train process\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss: {:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    print(time.perf_counter()-t1)\n",
    "\n",
    "    # validate\n",
    "    net.eval()  \n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += (predict_y == val_labels.to(device)).sum().item()\n",
    "        val_accurate = acc / val_num\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "        print('[epoch %d] train_loss: %.3f  test_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / step, val_accurate))\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
